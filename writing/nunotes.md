# TODO

## Model
- binding operation
    - C -> A -> B -> D   becomes   C -> AB -> D
- learning at multiple levels
    - build into ID vectors of chunks?
    - do explicitly?
- reconsider learning algo
- generalization
    - try complete on comprehension task
    - neighbor not 0 - 1

## Analysis
- grammaticality measure
    - chunkedness for all pairs not just actual chunks..
- complete scrambling
- perplexity?

## Abstract
- "we used a modified BLEU score"
- vague, but clear that it's been implemented


# MISC

- Reading time data for evaluating broad-coverage models of English sentence processing
- Cowan (2000) for choice of 4 window size

- competitive queeuing
    - competition among chunks



- should generalization occur after trying normal chunkiness?
- how to combine the two measures