
- Reading time data for evaluating broad-coverage models of English sentence processing
- Cowan (2000) for choice of 4 window size

- competitive queeuing
    - competition among chunks

- use complete generalization
- ngram compare size of training set to real life
- probgraph

- chunkedness for all pairs not just actual chunks..


- should generalization occur after trying normal chunkiness?
- how to combine the two measures

# TODO
- complete scrambling
- perplexity?
- correct for smoothing using clean up ala Plate
- generalization not 0 - 1

# Abstract
"we used a modified BLEU score"
vague, but clear that it's been implemented

